{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create session\n",
    "appName = \"data processing in spark\"\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".appName(appName) \\\n",
    ".config(\"spark.some.config.option\", \"some-value\") \\\n",
    ".getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayOfMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|        19|        5|     DL|          11433|        13303|      -3|       1|\n",
      "|        19|        5|     DL|          14869|        12478|       0|      -8|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightSchema = StructType([\n",
    "    StructField(\"DayOfMonth\", IntegerType(), False),\n",
    "    StructField(\"DayOfWeek\", IntegerType(), False),\n",
    "    StructField(\"Carrier\", StringType(), False),\n",
    "    StructField(\"OriginAirportID\", IntegerType(), False),\n",
    "    StructField(\"DestAirportID\", IntegerType(), False),\n",
    "    StructField(\"DepDelay\", IntegerType(), False),\n",
    "    StructField(\"ArrDelay\", IntegerType(), False)\n",
    "])\n",
    "\n",
    "flights = spark.read.csv('C:/Users/aayushi srivastava/Documents/AayushiSrivastavaJobSearch/PySparkProjects/dataset/flights.csv', schema = flightSchema, header = True)\n",
    "flights.show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----+--------------------+\n",
      "|airport_id|       city|state|                name|\n",
      "+----------+-----------+-----+--------------------+\n",
      "|     10165|Adak Island|   AK|                Adak|\n",
      "|     10299|  Anchorage|   AK|Ted Stevens Ancho...|\n",
      "+----------+-----------+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airportSchema = StructType([\n",
    "    StructField(\"airport_id\",IntegerType(), False),\n",
    "    StructField(\"city\", StringType(), False),\n",
    "    StructField(\"state\", StringType(), False),\n",
    "    StructField(\"name\", StringType(), False)\n",
    "])\n",
    "\n",
    "airports = spark.read.csv('C:/Users/aayushi srivastava/Documents/AayushiSrivastavaJobSearch/PySparkProjects/dataset/airports.csv',header =True, schema =airportSchema)\n",
    "airports.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|          city|count|\n",
      "+--------------+-----+\n",
      "|       Phoenix|89720|\n",
      "|         Omaha|13487|\n",
      "|Raleigh/Durham|28301|\n",
      "+--------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#merge two dataframes and (flights and airports) and show how many flights from each city\n",
    "flightsByOrigin = flights.join(airports,flights.OriginAirportID == airports.airport_id).groupBy(\"city\").count()\n",
    "flightsByOrigin.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original data rows: 2702218\n",
      "Number of data rows after deleting duplicate rows 2696657\n",
      "Number of duplicated Data 5561\n"
     ]
    }
   ],
   "source": [
    "#Drop duplicated data and calculate how many duplicated data\n",
    "\n",
    "# count number of original data rows\n",
    "n1 = flights.count()\n",
    "print(\"Number of original data rows:\",n1)\n",
    "\n",
    "#count data rows after deleting duplicated data\n",
    "n2 = flights.dropDuplicates().count()\n",
    "print(\"Number of data rows after deleting duplicate rows\", n2)\n",
    "\n",
    "#count duplicate data\n",
    "n3 = n1 - n2\n",
    "print(\"Number of duplicated Data\", n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|height|\n",
      "+----+---+------+\n",
      "|Rony| 27|   168|\n",
      "|Rony| 15|   165|\n",
      "|Rony| 27|   168|\n",
      "+----+---+------+\n",
      "\n",
      "+----+---+------+\n",
      "|name|age|height|\n",
      "+----+---+------+\n",
      "|Rony| 27|   168|\n",
      "|Rony| 15|   165|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#specify duplicate criteria by certain column\n",
    "df = spark.createDataFrame([(\"Rony\",27,168),\n",
    "                            (\"Rony\",15,165),\n",
    "                            (\"Rony\",27,168)],\n",
    "                          [\"name\",\"age\",\"height\"])\n",
    "df.show()\n",
    "df.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|height|\n",
      "+----+---+------+\n",
      "|Rony| 27|   168|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.dropDuplicates(['name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of missing value rows:  5561\n"
     ]
    }
   ],
   "source": [
    "#Handle Missing Data\n",
    "#Delete row if there is atleast one (column) missing data\n",
    "flightsNoMissingValue = flights.dropDuplicates().dropna(\n",
    "how = 'any', subset=[\"ArrDelay\", \"DepDelay\"]) #use how=\"all\" for all column missing data\n",
    "numberOfMissingValueAny = n1 - flightsNoMissingValue.count()\n",
    "print(\"number of missing value rows: \", numberOfMissingValueAny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean ArrDelay:  6.6550108096386005\n",
      "mean DepDelay:  10.510732294729737\n",
      "+------------------+\n",
      "|     avg(ArrDelay)|\n",
      "+------------------+\n",
      "|6.6550108096386005|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fill the missing data using mean of each corresponding column data\n",
    "#take mean value\n",
    "meanArrDelay = flights.groupBy().avg(\"ArrDelay\").take(1)[0][0]\n",
    "print(\"mean ArrDelay: \",meanArrDelay)\n",
    "meanDepDelay = flights.groupBy().avg(\"DepDelay\").take(1)[0][0]\n",
    "print(\"mean DepDelay: \",meanDepDelay)\n",
    "#drop duplicated data and fill missing value with mean value\n",
    "flightscleanData = flights.fillna(\n",
    "{'ArrDelay': meanArrDelay, 'DepDelay': meanDepDelay})\n",
    "\n",
    "flights.groupBy().avg(\"ArrDelay\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|          DepDelay|          ArrDelay|\n",
      "+-------+------------------+------------------+\n",
      "|  count|           2702218|           2702218|\n",
      "|   mean|10.510732294729737|6.6550108096386005|\n",
      "| stddev| 36.02975608466141| 38.54758423679155|\n",
      "|    min|               -63|               -94|\n",
      "|    max|              1863|              1845|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Explore the statistics of data\n",
    "flightscleanData.describe('DepDelay','ArrDelay').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation between departure delay and arrival delay:  0.9392560468773389\n"
     ]
    }
   ],
   "source": [
    "#calculate the correlation between two variables to know whether the variable is related to each other or not\n",
    "correlation = flightscleanData.corr('DepDelay','ArrDelay')\n",
    "print(\"correlation between departure delay and arrival delay: \",correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

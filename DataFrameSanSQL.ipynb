{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create session in order to be capable of accessing all Spark API\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".appName(\"Intro to Spark DataFrame\") \\\n",
    ".config(\"spark.some.config.option\",\"some-value\") \\\n",
    ".getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+----------------+------+-------+\n",
      "|      Date| Time|      City|            Item| Total|Payment|\n",
      "+----------+-----+----------+----------------+------+-------+\n",
      "|2012-01-01|09:00|  San Jose|  Men's Clothing|214.05|   null|\n",
      "|2012-01-01|09:00|Fort Worth|Women's Clothing|153.57|   null|\n",
      "|2012-01-01|09:00| San Diego|           Music| 66.08|   null|\n",
      "+----------+-----+----------+----------------+------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#define data schema for file we want to read\n",
    "purchase_schema = StructType([\n",
    "    StructField(\"Date\", DateType(), True),\n",
    "    StructField(\"Time\", StringType(), True),\n",
    "    StructField(\"City\", StringType(), True),\n",
    "    StructField(\"Item\", StringType(), True),\n",
    "    StructField(\"Total\", FloatType(), True),\n",
    "    StructField(\"Payment\", FloatType(), True)\n",
    "])\n",
    "\n",
    "purchaseDataframe = spark.read.csv(\n",
    "\"C:/Users/aayushi srivastava/Documents/AayushiSrivastavaJobSearch/PySparkProjects/dataset/purchases.csv\", header = True,\n",
    "schema = purchase_schema, sep = \"\\t\")\n",
    "\n",
    "purchaseDataframe.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  4138476\n",
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Item: string (nullable = true)\n",
      " |-- Total: float (nullable = true)\n",
      " |-- Payment: float (nullable = true)\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|             Total|\n",
      "+-------+------------------+\n",
      "|  count|           4138476|\n",
      "|   mean|249.96108549398525|\n",
      "| stddev| 144.3174111542959|\n",
      "|    min|               0.0|\n",
      "|    max|            499.99|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#count number of rows in our dataframe\n",
    "num_rows = purchaseDataframe.count()\n",
    "print(\"Number of rows: \",num_rows)\n",
    "\n",
    "#show our dataframe schema\n",
    "purchaseDataframe.printSchema()\n",
    "\n",
    "#show statistic of the data we want\n",
    "purchaseDataframe.describe('Total').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|      city| Total|\n",
      "+----------+------+\n",
      "|  San Jose|214.05|\n",
      "|Fort Worth|153.57|\n",
      "| San Diego| 66.08|\n",
      "+----------+------+\n",
      "only showing top 3 rows\n",
      "\n",
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- Total: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create new dataframe from \"city\" and \"Total\" columns\n",
    "newDataframe = purchaseDataframe.select(purchaseDataframe['city'],purchaseDataframe['Total'])\n",
    "newDataframe.show(3)\n",
    "newDataframe.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|      City|(Total + 10)|\n",
      "+----------+------------+\n",
      "|  San Jose|      224.05|\n",
      "|Fort Worth|      163.57|\n",
      "| San Diego|       76.08|\n",
      "+----------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#adding constant value of 10 to every row data in column 'Total'\n",
    "purchaseDataframe.select(purchaseDataframe['City'],\n",
    "                        purchaseDataframe['Total']+10).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+-------------------+------+-------+\n",
      "|      Date| Time|      City|               Item| Total|Payment|\n",
      "+----------+-----+----------+-------------------+------+-------+\n",
      "|2012-01-01|09:00|  San Jose|     Men's Clothing|214.05|   null|\n",
      "|2012-01-01|09:00|Pittsburgh|       Pet Supplies|493.51|   null|\n",
      "|2012-01-01|09:00|     Omaha|Children's Clothing|235.63|   null|\n",
      "+----------+-----+----------+-------------------+------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filtering dataframe\n",
    "#filter only row data whose 'Total' column value > 200\n",
    "purchaseDataframe.filter(purchaseDataframe['Total'] > 200).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----------+----------------+------+-------+\n",
      "|      Date| Time|       City|            Item| Total|Payment|\n",
      "+----------+-----+-----------+----------------+------+-------+\n",
      "|2012-10-07|11:11|Albuquerque|    Pet Supplies| 308.7|   null|\n",
      "|2012-10-07|11:40|Albuquerque|            Toys|299.63|   null|\n",
      "|2012-10-07|11:13|Albuquerque|Women's Clothing|419.49|   null|\n",
      "|2012-10-07|10:39|Albuquerque|    Pet Supplies| 401.3|   null|\n",
      "+----------+-----+-----------+----------------+------+-------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sorting dataframe by certain column\n",
    "sortedByCity = purchaseDataframe.orderBy('City').show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|           City|count|\n",
      "+---------------+-----+\n",
      "|North Las Vegas|40013|\n",
      "|        Phoenix|40333|\n",
      "|          Omaha|40209|\n",
      "|      Anchorage|39806|\n",
      "|        Anaheim|40086|\n",
      "+---------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculating number of transactions in each city\n",
    "numTransactionEachCity = purchaseDataframe.groupBy(\"City\").count()\n",
    "numTransactionEachCity.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+-------------------+------+-------+-----+\n",
      "|      Date| Time|      City|               Item| Total|Payment|index|\n",
      "+----------+-----+----------+-------------------+------+-------+-----+\n",
      "|2012-01-01|09:00|  San Jose|     Men's Clothing|214.05|   null|    0|\n",
      "|2012-01-01|09:00|Fort Worth|   Women's Clothing|153.57|   null|    1|\n",
      "|2012-01-01|09:00| San Diego|              Music| 66.08|   null|    2|\n",
      "|2012-01-01|09:00|Pittsburgh|       Pet Supplies|493.51|   null|    3|\n",
      "|2012-01-01|09:00|     Omaha|Children's Clothing|235.63|   null|    4|\n",
      "|2012-01-01|09:00|  Stockton|     Men's Clothing|247.18|   null|    5|\n",
      "|2012-01-01|09:00|    Austin|            Cameras| 379.6|   null|    6|\n",
      "+----------+-----+----------+-------------------+------+-------+-----+\n",
      "only showing top 7 rows\n",
      "\n",
      "+----------+-----+----------+-------------------+------+-------+-----+\n",
      "|      Date| Time|      City|               Item| Total|Payment|index|\n",
      "+----------+-----+----------+-------------------+------+-------+-----+\n",
      "|2012-01-01|09:00| San Diego|              Music| 66.08|   null|    2|\n",
      "|2012-01-01|09:00|Pittsburgh|       Pet Supplies|493.51|   null|    3|\n",
      "|2012-01-01|09:00|     Omaha|Children's Clothing|235.63|   null|    4|\n",
      "+----------+-----+----------+-------------------+------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Indexing and Accessing DataFrame\n",
    "#(create new column with inccremental id.then we can access using .filter to incremental id)\n",
    "\n",
    "#importing monotonically increasing id\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "newPurchasedDataframe = purchaseDataframe.withColumn(\n",
    "\"index\", monotonically_increasing_id())\n",
    "newPurchasedDataframe.show(7)\n",
    "\n",
    "row2till4 = newPurchasedDataframe.filter((newPurchasedDataframe['index'] >= 2) &\n",
    "                                        (newPurchasedDataframe['index'] <= 4))\n",
    "row2till4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Total|\n",
      "+-----+\n",
      "|66.08|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Then, to access it by row and column use \".select()\"\n",
    "dataRow2ColumnTotal = newPurchasedDataframe.filter(newPurchasedDataframe['index'] == 2).select('Total')\n",
    "dataRow2ColumnTotal.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "| Total|Payment|\n",
      "+------+-------+\n",
      "|214.05|   null|\n",
      "|153.57|   null|\n",
      "| 66.08|   null|\n",
      "+------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using sql query in dataframe\n",
    "#we need to make sql temporary view for our dataframe\n",
    "purchaseDataframe.createOrReplaceTempView(\"purchaseSql\")\n",
    "\n",
    "#select 'Total' and \"Payment\" column from our sql temporary view\n",
    "anotherDataframe = spark.sql(\"SELECT Total, Payment FROM purchasesql\")\n",
    "anotherDataframe.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----------+-------------------+------+-------+\n",
      "|      Date| Time|       City|               Item| Total|Payment|\n",
      "+----------+-----+-----------+-------------------+------+-------+\n",
      "|2012-10-07|10:46|Albuquerque|Children's Clothing|143.48|   null|\n",
      "|2012-10-07|11:18|Albuquerque|             Crafts|475.77|   null|\n",
      "|2012-10-07|11:11|Albuquerque|       Pet Supplies| 308.7|   null|\n",
      "+----------+-----+-----------+-------------------+------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sorting data by certain column\n",
    "#sorting data by city column alphabetically\n",
    "orderByCity = spark.sql(\"SELECT * FROM purchasesql ORDER BY City\")\n",
    "orderByCity.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----------+--------------------+------+-------+\n",
      "|      Date| Time|       City|                Item| Total|Payment|\n",
      "+----------+-----+-----------+--------------------+------+-------+\n",
      "|2012-10-07|10:32|     Toledo|               Music|414.82|   null|\n",
      "|2012-10-07|10:32| Chesapeake|      Sporting Goods|377.16|   null|\n",
      "|2012-10-07|10:32|   San Jose|Consumer Electronics|234.27|   null|\n",
      "|2012-10-07|10:32|Bakersfield|   Health and Beauty| 375.2|   null|\n",
      "+----------+-----+-----------+--------------------+------+-------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filter data with 'Total' column value > 200 and sort them by Payment column data\n",
    "filterAndSortWithSQL = spark.sql(\"SELECT * FROM purchasesql WHERE Total > 200 ORDER BY payment\")\n",
    "filterAndSortWithSQL.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
